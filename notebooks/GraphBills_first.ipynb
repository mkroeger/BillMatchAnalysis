{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import networkx as nx\n",
    "import os \n",
    "import json \n",
    "import matplotlib\n",
    "import operator\n",
    "#matplotlib.use('Agg')\n",
    "\n",
    "from graphlab import SGraph, Vertex, Edge, pagerank\n",
    "\n",
    "#better do a tree walk\n",
    "def getMatchedBills(matchDirPath,ncount=-1):\n",
    "   matchedBills = list() \n",
    "   labels = ['modelBill','stateBill','matchPrecent','modelBillContent','stateBillContent']\n",
    "   walkOpj =  os.walk(matchDirPath)\n",
    "   threshold = 0\n",
    "   for (dirpath, dirnames, filenames) in walkOpj:\n",
    "        for fname in filenames:\n",
    "            if \"part\" not in fname: continue\n",
    "            #Keep only top ncount bills \n",
    "            if threshold > ncount and ncount > 0: continue     \n",
    "            threshold += 1    \n",
    "            ff = os.path.join(dirpath,fname)\n",
    "            for line in open(ff).readlines():\n",
    "                if line.strip(): matchedBills.append(dict(zip(labels, line.split('^^^'))))\n",
    "\n",
    "   return matchedBills\n",
    "\n",
    "def graphStats(G,detailed=False):\n",
    "    # Can probably do more https://networkx.github.io/documentation/latest/reference/functions.html\n",
    "    print \"-------------------------------------\"\n",
    "    print \"Number of edges in the graph: \", G.number_of_edges()\n",
    "    print \"Number of nodes in the graph: \", G.number_of_nodes()\n",
    "    print \"-------------------------------------\"\n",
    "    if detailed:\n",
    "        print \"Detailed graph statistics:\" \n",
    "        for line in nx.generate_edgelist(G):\n",
    "            print(line)\n",
    "    #In case of SGraph print Gmatches.get_edges().print_rows(num_rows=40, num_columns=3)         \n",
    "            \n",
    "\n",
    "def fillGraph(matchedBills,pr_preselect,keep_top_n=9999999):\n",
    "    Gmatches = nx.Graph()\n",
    "    #Read the dataset\n",
    "    for mb in matchedBills:\n",
    "        #load all nodes/edges into graph \n",
    "        if mb['modelBill'] != mb['stateBill']:\n",
    "            state1 = mb['modelBill'].split(\"/\")[-4]\n",
    "            year1 = mb['modelBill'].split(\"/\")[-3] \n",
    "            state2 = mb['stateBill'].split(\"/\")[-4]\n",
    "            year2 = mb['stateBill'].split(\"/\")[-3]   \n",
    "            label1 = state1+year1+\"_\"+mb['modelBill'].split(\"/\")[-1].rstrip(\".txt\")\n",
    "            label2 = state2+year2+\"_\"+mb['stateBill'].split(\"/\")[-1].rstrip(\".txt\")\n",
    "            #use inverse similarity as weight\n",
    "            Gmatches.add_edge(label1,label2,weight=1./float(mb['matchPrecent']))\n",
    "\n",
    "    if keep_top_n!=9999999: \n",
    "        for gnode in Gmatches.nodes():\n",
    "            sorted_edges = sorted(Gmatches.edges(nbunch=[gnode],data=True), key=lambda (source,target,data): data['weight'],reverse=True)\n",
    "            subset_to_remove = tuple(sorted_edges[:-keep_top_n])\n",
    "            #print len(sorted_edges)\n",
    "            #print \"Remove those \", sorted_edges[:-keep_top_n]\n",
    "            #print \"Keep those \", sorted_edges[-keep_top_n:]\n",
    "            for tuple_to_remove in subset_to_remove:\n",
    "                Gmatches.remove_edge(*tuple_to_remove[:2])\n",
    "         \n",
    "    if pr_preselect > 0: \n",
    "        pr = nx.pagerank(Gmatches, alpha=0.9)\n",
    "        for gnode in Gmatches.nodes():\n",
    "            subset_to_remove = tuple(Gmatches.edges(nbunch=[gnode],data=True))\n",
    "            if pr[gnode] < pr_preselect:\n",
    "                for tuple_to_remove in subset_to_remove:\n",
    "                    Gmatches.remove_edge(*tuple_to_remove[:2])\n",
    "                    #Gmatches.remove_node(gnode)\n",
    "                    \n",
    "        #remove zero degree nodes\n",
    "        to_remove = [node for node,degree in Gmatches.degree().items() if degree < 2]\n",
    "        Gmatches.remove_nodes_from(to_remove)\n",
    "                \n",
    "        graphStats(Gmatches)\n",
    "\n",
    "    return Gmatches\n",
    "\n",
    "\n",
    "def fillSGraph(matchedBills):\n",
    "    Gmatches = SGraph()\n",
    "    #Read the dataset\n",
    "    weights = list()\n",
    "    for mb in matchedBills:\n",
    "        #load all nodes/edges into graph \n",
    "        if mb['modelBill'] != mb['stateBill']:\n",
    "            label1 = mb['modelBill'].split(\"/\")[-1]\n",
    "            label2 = mb['stateBill'].split(\"/\")[-1]\n",
    "            #use inverse similarity as weight\n",
    "            #Gmatches.add_edge(label1,label2,weight=1./float(mb['matchPrecent']))\n",
    "            vertices = list()\n",
    "            vertices.append(Vertex(label1))\n",
    "            vertices.append(Vertex(label2))\n",
    "            Gmatches = Gmatches.add_vertices(vertices)\n",
    "            Gmatches = Gmatches.add_edges(Edge(label1,label2))\n",
    "            weights.append(1./float(mb['matchPrecent']))\n",
    "            \n",
    "    Gmatches.edges['weight'] = weights  \n",
    "    return Gmatches    \n",
    "    \n",
    "def pageRankDumpReport(G,gtype=\"Networkx\"):\n",
    "    if gtype == \"Networkx\":\n",
    "        #PageRank\n",
    "        #alpha : float, optional\n",
    "        #Damping parameter for PageRank, default=0.85.\n",
    "        try:\n",
    "            pr = nx.pagerank(G, alpha=0.9)\n",
    "            json.dump(pr, open(\"graph_pagerank.json\",'w'))\n",
    "            print \"Saving PageRank report to: \", \"graph_pagerank.json\"\n",
    "        except: print \"Too many edges got removed. Graph is disjoint... Adjust parameters for fillGraph\"\n",
    "    else:\n",
    "        pr = pagerank.create(G)\n",
    "        pr['pagerank'].save(\"SGraph_pagerank\")\n",
    "        #print pr['pagerank'].print_rows(num_rows=10, num_columns=3)  \n",
    "        #>>> pr_out = pr['pagerank']     # SFrame\n",
    "        #>>> g.vertices['pagerank'] = pr['graph'].vertices['pagerank']\n",
    "\n",
    "            \n",
    "def pageRankShowReport(G):\n",
    "    #PageRank\n",
    "    #alpha : float, optional\n",
    "    #Damping parameter for PageRank, default=0.85.\n",
    "    pr = nx.pagerank(G, alpha=0.9)\n",
    "    sorted_pr = sorted(pr.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    print len(pr), \" \", len(sorted_pr)\n",
    "    for node,weight in sorted_pr:\n",
    "        print \"Next node: \", node, \" has PR weight: \", weight\n",
    "        print \"++++++++++++++++++++++++\"\n",
    "        print \"It has following links: \"\n",
    "        for from_node,to_node in G.edges(nbunch=[node]):\n",
    "            print to_node\n",
    "\n",
    "\n",
    "def saveGraphJSON(G):\n",
    "    from networkx.readwrite import json_graph\n",
    "    for n in G:\n",
    "        G.node[n]['name'] = n\n",
    "    # write json formatted data\n",
    "    d = json_graph.node_link_data(G) # node-link format to serialize\n",
    "    # write json\n",
    "    print \"Saving graph to: \", \"graph.json\"\n",
    "    json.dump(d, open(\"graph.json\",'w'))\n",
    "\n",
    "    \n",
    "def getToHighlight(G):\n",
    "    print \"Highlights nodes, for SGraph only!\"\n",
    "    pr = pagerank.create(G)\n",
    "    pr_out = pr['pagerank']     # SFrame\n",
    "    #print pr_out['__id'] #['pagerank'] \n",
    "    \n",
    "    important= set()\n",
    "    for a,b in zip(pr_out['__id'],pr_out['pagerank']):\n",
    "        if b > 0.2: important.add(a)  \n",
    "        print b\n",
    "    \n",
    "    return important   \n",
    "    \n",
    "    \n",
    "def displayGraphQuickly(G,coloring=\"by_weight\",plot_name=\"weighted_graph.png\",gtype=\"Networkx\"):\n",
    "\n",
    "    if gtype == \"Networkx\":     \n",
    "        G2 = G.copy()\n",
    "\n",
    "        elarge=[(u,v) for (u,v,d) in G2.edges(data=True) if d['weight'] >0.1]\n",
    "        esmall=[(u,v) for (u,v,d) in G2.edges(data=True) if d['weight'] <=0.1]\n",
    "        \n",
    "        #FIXME\n",
    "        if coloring != \"by_weight\": \n",
    "            pass\n",
    "            #pr = nx.pagerank(G2, alpha=0.9)\n",
    "            #sorted_pr = sorted(pr.items(), key=operator.itemgetter(1),reverse=True)\n",
    "            #elarge=[(node,weight) for node,weight in sorted_pr if weight >0.1]\n",
    "            #esmall=[(u,v) for (u,v,d) in G2.edges(data=True) if d['weight'] <=0.1]\n",
    "\n",
    "        pos=nx.spring_layout(G2) # positions for all nodes\n",
    "\n",
    "        # nodes\n",
    "        nx.draw_networkx_nodes(G2,pos,node_size=700)\n",
    "\n",
    "        # edges\n",
    "        nx.draw_networkx_edges(G2,pos,edgelist=elarge,\n",
    "                width=2)\n",
    "        nx.draw_networkx_edges(G2,pos,edgelist=esmall,\n",
    "                width=2,alpha=0.5,edge_color='r',style='dashed')\n",
    "\n",
    "        # labels\n",
    "        nx.draw_networkx_labels(G2,pos,font_size=9,font_family='sans-serif')\n",
    "\n",
    "        matplotlib.pyplot.axis('off')\n",
    "        matplotlib.pyplot.savefig(plot_name) # save as png\n",
    "    else:\n",
    "        important = list(getToHighlight(Gmatches))\n",
    "        Gmatches.show(vlabel='id', highlight=important, elabel='weight', elabel_hover=True)\n",
    "\n",
    "\n",
    "        \n",
    "#Slightly modified Networkx's dfs_tree method\n",
    "def dfs_custom_tree(G, source=None):\n",
    "    T = nx.Graph()\n",
    "    if source is None:\n",
    "        T.add_nodes_from(G)\n",
    "    else: \n",
    "        T.add_node(source)\n",
    "    #print \"All those edges\"\n",
    "    #for e in nx.dfs_edges(G,source):\n",
    "    #    print e\n",
    "    T.add_edges_from(nx.dfs_edges(G,source))\n",
    "    #FIXME assign weights back to the graph T\n",
    "    for u,v,g in G.edges(data=True):\n",
    "        try:\n",
    "            T[u][v]['weight'] = G[u][v]['weight']\n",
    "        except: continue\n",
    "    return T\n",
    "\n",
    "#Mostly to preserve the weighgts\n",
    "def bfs_custom_tree(G, reverse=False):\n",
    "    T = nx.Graph()\n",
    "    #in some sense, picking a random node...\n",
    "    source = G.nodes()[0]\n",
    "    T.add_node(source)\n",
    "    T.add_edges_from(nx.bfs_edges(G,source,reverse=reverse))\n",
    "    #FIXME assign weights back to the graph T\n",
    "    for u,v,g in G.edges(data=True):\n",
    "        try:\n",
    "            T[u][v]['weight'] = G[u][v]['weight']\n",
    "        except: continue\n",
    "    return T\n",
    "\n",
    "\n",
    "def dfsTraverse(G,doPreorder=True):\n",
    "    if doPreorder: return nx.dfs_preorder_nodes(G)   \n",
    "    else: return nx.dfs_postorder_nodes(G)\n",
    "\n",
    "def dfsDescribe(G,edgesOnly=True):\n",
    "    G2 = G.copy()\n",
    "    if edgesOnly: return nx.dfs_edges(G2)\n",
    "    else: return dfs_custom_tree(G2) #,'EO165_Issued.txt')\n",
    "\n",
    "def bfsDescribe(G,edgesOnly=True):\n",
    "    G2 = G.copy()\n",
    "    if edgesOnly: return nx.bfs_edges(G2)\n",
    "    else: return bfs_custom_tree(G2) #,'EO165_Issued.txt')\n",
    "\n",
    "def dijkstraDumpReport(G,printOnScreen=False):\n",
    "    paths = nx.all_pairs_dijkstra_path_length(G, weight='weight')\n",
    "    print type(paths)\n",
    "    json.dump(paths, open(\"graph_dijkstra.json\",'w'))\n",
    "    print \"Saving all the Dijkstra lengths to: \", \"graph_dijkstra.json\"\n",
    "    if printOnScreen:\n",
    "        for path in paths.keys():\n",
    "            print \"------------------------------------------\"\n",
    "            print path, \"  \", paths[path]\n",
    "            print \"\\n\"\n",
    "\n",
    "            \n",
    "#Read the dataset\n",
    "matchedBills = getMatchedBills('/Users/asvyatko/Desktop/Spark_tests/matches_3states90/',5000)   \n",
    "Gmatches = fillGraph(matchedBills, 0.00006) #,3)   \n",
    "#print getToHighlight(Gmatches)\n",
    "#print Gmatches.get_edges().print_rows(num_rows=40, num_columns=3) \n",
    "\n",
    "#get stats about the newly filled graph\n",
    "#graphStats(Gmatches)\n",
    "\n",
    "#dump graph to JSON as a node-link structure\n",
    "#saveGraphJSON(Gmatches) #provide argument to specify in what format do you want it saved\n",
    "#calculate pagerank\n",
    "#pageRankDumpReport(Gmatches,\"SGraph\")\n",
    "#pageRankShowReport(Gmatches)\n",
    "\n",
    "#Djikstra\n",
    "#dijkstraDumpReport(Gmatches,True) \n",
    "\n",
    "#display the graph\n",
    "displayGraphQuickly(Gmatches,\"by_weight\",\"weighted_graph.png\",\"Networkx\")   \n",
    "\n",
    "#show the DFS tree structure\n",
    "#Gdfs = dfsDescribe(Gmatches,False)\n",
    "#graphStats(Gdfs)\n",
    "#displayGraphQuickly(Gdfs,\"weighted_graph_dfs.png\") \n",
    "\n",
    "#Gbfs = bfsDescribe(Gmatches,False)\n",
    "#graphStats(Gbfs)\n",
    "#displayGraphQuickly(Gbfs,\"weighted_graph_bfs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
